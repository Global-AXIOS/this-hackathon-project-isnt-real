  Not too many, as the scope of this project was relatively small. It was mainly debugging, and figuring out how to settle ties (which we have to be random) Get data out of Spark AR to control L-ISA Software.  Efficiency issues, long runtime   Not too many, as the scope of this project was relatively small. It was mainly debugging, and figuring out how to settle ties (which we have to be random) Get data out of Spark AR to control L-ISA Software.  Efficiency issues, long runtime Laptop battery life management. -Inexperience: Going into the project, Ethan had a working knowledge of Godot but no solid conceptual grasp of real-time 3D particle-based fluid simulation. Matt came into the project with neither a working understanding of Godot nor a conceptual grasp of real-time 3D particle-based fluid simulation. While Matt's lack of Godot experience was surmountable in a reasonable amount of time, the collective non-understanding of real-time 3D particle-based fluid simulation was a dealbreaker. Towards the end of the first night of work, we decided to drop the fluid simulation altogether and pivot to experimenting with the Leap Motion tools included in the plugin.   Debugging, keeping track of paths.  Github  Beyond the necessary bug squashing that comes with any code, we had issues arise from using technologies we were unfamiliar with and attempting to link them all together in a cohesive user experience.Had issues directing users from the log in pageHad issues using promises in JSStruggled to properly authenticate with GCP   We tried to use machine learning to analyse the frequencies and train the machine to recognize a chainsaw noise. However, we found this to be more difficult than our skill set allowed, so we shifted gears and manually calibrated the range of the chainsaw decibels.  We were beginners and we did not know how to build a website, yet we overcame the challenge Unfamiliarity with the new concept of app making     None of us have used Unity or any sort of mixed reality/3D game development before. Additionally, we had originally planned to use Google's DialogFlow instead of IBM Watson, since we were already using their ARCore SDK. However, Google had deprecated and shut down their previous version 2 months ago, and there are no longer any Unity plugins for DialogFlow. We then had to shift gears and look for a new NLP tool, and since we had also not used IBM Watson with Unity before, this was also a learning curve. There were also no mentors that had experience with the technologies we wanted to use. There was also limited documentation on everything given how new AR is.  Our codes to translate do not work as expected. Other technical devices were not working. Deciding out of the 6 coordinates, which anticipates the most accurately if the driver is feeling drowsy. We faced many difficulties while working on this. Firstly, it was a little difficult to get an open-source dataset from the internet, and after searching for a long time, we got a dataset on SKIN CANCER MNIST from Kaggle. Secondly, it was to identify the right model architecture, which could potentially learn the subtle features that differentiate one skin-disease from others. While training the network, tuning the hyperparameters, like the number of neurons in the final layer, learning rate, dropout probabilities, etc. took a substantial amount of our time. Combining machine learning pipeline to the website without compromising any features is one of the tough ones, as we didn’t stop to just make a mock-up but wanted to complete it as a whole.    Originally, we wanted to create a website to make the app more accessible, however we did not have the knowledge to host it. We ran into some aesthetic challenges, such as the difficulty of creating a visually pleasing interface because we did not use a scripting language. The main challenge was getting the audio to play in the applet and having it play at the speed we hoped. Additionally, we did not have enough time to implement the ability to play the various recordings concurrently.   One of the main issues we ran into was the drifting of the model interface while we were working in parallel. When we met to prepare to merge our halves together, we faced more complications than expected because we were essentially working with two dialects of the model. Furthermore, we ran into issues with separation of concerns, as we were not always clear on what parts of the pipeline our codebases were supposed to handle.   The Alexa Developer console was somewhat difficult to work with because its instructions were mostly in fairly long courses, and we did not have the time to do those. We had to search around to find quick, easy explanations of how to use the developer console, which made it somewhat difficult to use. The phrasing changes that we made in Daisy Daisy also does not function on the physical Alexa.  Cleaning the noise from the software defined radio and decoding the signal presented a challenge. Differentiating the background noise from communications and clipping only when necessary to prevent data overload also presented issues.  Programming how to upload images Using python turned out to be very challenging for both of us because we had 0% knowledge of this powerful language. It took us a lot of time to configure Kivy into our laptops, because it would cause random errors while downloading the libraries. We wasted around 4-5 hours resolving these errors. Other than that, it was super challenging for us when we started coding, because we knew nothing about python.  Learning Unity on the spot was particularly challenging, albeit fun. As a team, we all participated in the Unity CrashCourse Workshop for a quick introduction. Nevertheless, it was tough figuring out how to take advantage of the existing library, how to manipulate text and display, especially with the program rendering bottom up, and programming collisions of the sprites was challenging. Overall, it was a fruitful experience attempting to learn a different language in a short amount of time.  Everything   Feasibility: Our original idea is to make the voice assistant recognize whether user has potential symptoms of mental illness and then provide real-time assistance 24/7. If a user demonstrates severe mental stress or depression, the voice assistant will then seamlessly connect a counselor with the user during the conversion. However, this idea is hard to achieve in reality. Since this service is available for users at any time, it might be difficult to connect users with a counselor at midnight, which involves certain operational costs that cannot be avoided.Training data: Currently, we manually typed in possible conversations between a student with potential mental illness symptoms and the voice assistant. Since it is not a comprehensive dataset, there are use cases that we did not include. For this to be said, our current outcome provides a solid framework that combines counseling feature with voice assistant.User Utterance:How to understand user utterance in a broader context of the dialogue is the main challenge while developing the add-on counseling feature of Google Assistant. In Google Assistant’s developer platform, we can add parameters such as dates, times, and places that define which parts of the user utterances to extract. However, Google Assistant does not allow us to create parameters related to user’s emotions such as sadness, anger, and depression, which can largely improve its ability to identify user’s intentions behind his or her move (e.g. asking a question or making a complaint).   Our teammate who knows the most coding got sick last night and had to leave and another team member was too tired from her flight. We could not finish all of the code and had to work with what we had.  WIP time, time  competitors ...to have more advantages and features plus using technology   test    Lack of information  alternative energy           Blockstack is still pretty new and there's not a lot of documentation for it. A lot of the project was reverse engineering anything I could find on Google to understand how it actually worked.   c How to enact our privacy policy? How to integrate existing algorithms with nutritional factor database.How to do UI/UX design and use Adobe XD                   We had an original code that wouldn't allow the strings to work when we wanted to type in first and last names. We ran into the problem of our do-while loops not correctly working, but with revisions we were able to determine that we were missing our Break() function for it to properly close out the loop.        Find a person to develop my idea.     We agreed that I will complete project in one month, but i spend about 6 month, because project was for real production, and there was many problems that i must to solve.  As always it was integration with different knowledge sources         Because I wanted to build a game of high quality, I included alot of features which increased the scope. Besides the skill itself, I needed to build out the website, the database system for the in-skill leaderboards, and email system, and a content management framework. While building the skill itself, and all the other moving parts were quite a challenge and took lots of iteration to get right, I think the content management aspect was the most interesting challenge I had to face so I wanted to focus on that.Building a daily recurring game means more content every day. To make this word right and with accurate word recognition, I needed to include all of the solutions to the puzzles, including the themes, into the voice model. This means re-certifying with every new puzzle that is added. I could have taken a more risky approach and used an 'open' slot with SearchQuery, but I really wanted the accuracy to be top notch so I took the more involved approach.To get all the data into the skill, I needed a great way to manage the content. Instead of managing the puzzle content in code, I decided it would be way easier to use spreadsheets. In the spreadsheet I can fill in the solutions, the clues, and the themes.From there, I needed to get it into the slots of the skill, and access it from within my skill code. To do so, I built a number of deployment scripts. These scripts are used to do a number of things:Import the spreadsheet into code and convert it into JSON, so the skill code can use it to provide the right puzzlesAutomatically fill in dates and data for all the new puzzles that are addedRun some verification on the generated JSON file to make sure there are no duplicate dates, puzzleIds, etcTake all the words I need from the JSON file in the voice model, (clue answers and theme names) and open up the voice model json file, update the slot values, and save it back to disk so that I could use that to upload to the Alexa service.Upload all the puzzle data into MySql so the website has access to the correct puzzle dataThese scripts allow me to do all the data management I need in only a minute or so, saving me alot of time and potential errors in the future. With this system, I plan to create skill content every 2-3 months, and then update the skill with that data, giving me a nice worry-free window in case things are slow with certification. By automating the process, I can make all those above updates that are pretty far reaching into all of the infrastructure and code of the entire system, without touching the code myself. This really limits the vectors for failure and allows me to spend more of my time focusing on how to improve the game for customers.  The unstable public WiFi connection caused significant latency in media uploading.The CCAPI has limited usages, and caused compatibility issues on MacOS (could not set up). Authentication, UI flow  This was my first time working with APIs so it came with a big learning curve but I am glad I stuck with it and now I have a skill that is very valuable  We had a hard time finding APIs we could use that were free, and none of the challenge APIs did precisely what we expected them to do.  The design of voice and music was new for me, particularly in order to match it with the particular mood of the game.  Lack of electronic equipment such as biometric machines, hd web cameras, digital signature pad and PDAs.         There were so many options in the API we had to prioritize which were important. The LV was hard because we had to make a http request for each frame, pulling images from the camera. There were a lot of technologies that wound up needing to be used.    One bit challenge was around a team member's laptop deciding not work effectively part way though Wednesday.  They worked round it by using Code Pen and making commits through the GitHub web interface.Another challenge the team faced was in unclear division of tasks.  So two people ended up working on the same feature and another critical issued did not get worked on at all.Deploying to GitHub pages - the url used for the homepage is very important.Accomplishments that we are proud ofDeploying to GitHub pages with React.What we learnedHow to deploy React to GitHub pages.How to work with an Organization on GitHub (forking and Pull Requests).What's next for Cook from my PantrySalad/Sandwich/Smoothie roulette - creating light meals with 5 ingredients or less!Built WithjavascriptreactTry it outhack-for-fun.github.io      Submitted to    DeveloperWeek Austin 2019 Hackathon    Created by  Stephanie CaulleyJavaScript developer interested in social good/social impact.  My team won the Social Impact award at the 2019 WWC Austin Hackathon.jahongOf1 HongAllistair EverettSharath Teluisabellegiuong      After building the application, we realized that the architecture we setup will not let us run and collect real-time video data in background.    I had a hard time to separate the processing for normal Echo dot (model without GPS) and smartphone (with GPS). I found the most challenging part of this assignment was to get sort words into word families.          Niothing This was one of my first skills, so basically all the challenges you can think of!    Learning would be one of it. With my Majors being a completely different stream. I had to take in the aspects of a Computer Science student working on a project. Which gave me a whole new perspective on What I could do. Creating a space where users can access the digital portfolio on both desktops and mobile devices. There are challenges at every step, particularly with such a complex machine - steering setup needs to be revisited and some coding in the master-control system needs to be resolved. Big challenge at this point is to attract further funding to continue to develop the business of manufacturing electric vehicles.   I'm not extremely open source savy, so being able to put together multiple sources of documentation into one cohesive guide was pretty difficult for me.   Server to store information which we finally came up with integrating FirebaseBuilt WithjavaTry it outgithub.com    Created by  Filip SkotarskiFinTech, SaaS Being mainly an OpenEdge Consultant, a technical architect and App Evo / modernisation expert I was feeling strong on the process but when I start building the proto, I was not knowing nor the final customer system or database environment (originally was MapR data lake), nor I was knowing in details DataDirect HDP technology, nor I was having specific UI/UX designer or front end language skills (JavaScript / NativeScript). All started as an extremely appealing challenge... In the end, the lack of skills, that was a weakness, turned into a point of strength saying the simple truth to the customer: Progress simplify that big complexity for you to be on time, on target... a lot of them: webrtc, websockets, support mobile, learning the openshift platform ... all in a few days Using WebSockets with flask backend to run the training process of the models in an asynchronous manner.training the models on the cloud on-demand. Initially, we thought we won't be able to develop our project using a completely new platform and learning new tech stacks. But as we were working at least I thought that now I am a die-hard fan of the Red hat community. I want to become it's member now and so I wanted to use almost all the tools. But then our main intention was to make something productive and we had less time so we are going to present our prototype.   The main challenge is to understand what could be interesting to people. And developing the game can be even more challenging in this area, cause, for the most part, you can't validate your assumptions         Being able to link each page to each other and being able to edit the existing data from the database. Challenges with the react framework connecting with our APIs and our builds synching with github.All fixed!Time was a big hurdle as there were many more features we wanted to include that would make the entire process easier for the general public.   We wanted to find ways to disseminate information to a population of people who might not have modern technology, who might be distressed, or who might be concerned about their citizenship status and privacy. Since discretion and dignity is a major component to our model, we had to think of a way to present the information to the client that was obvious and intuitive to them, but not others. Finding a good location for the kiosk as well as designing a system that was intuitive was a challenge. Some of the challenges we ran into were using the google maps API and implementing an overlaid heat map of crime rates using polygons. These actions proved quite difficult and required lots of research and reading of the developer's guides and documentation. We also had to figure out how to process the large amounts of data from the polygon dataset to display the heatmap points, which required learning some JavaScript which we had no experience with. Getting an actual database to connect to our Node.js + Express application. Decided to use temporary containers.  Q: How do we ensure a massive following? A: Our target, with the homeless organization (St. Anthony's) in mind, is not to grab the most downloads, but to personalize a user experience for someone who wants to participate in volunteering but doesn't know how.  Q: How do we "humanize" the volunteering experience? A: Further along in the user journey, we hope to implement a growing relationship with a person in need via a partnership system. It would have to be executed through the homeless organization, however. Q: A massive part of a community experience is to encourage one another through "likes". Why don't we allow "likes" and "comments" in our social feed?A: We don't want the feed to be about the most amount of likes. However, we do want to advocate for each other and encourage others to join us in our volunteering journey. Perhaps we can implement this in a future feature as well, to send and receive hearts (via private messaging and notifications) and create and attend events through the app together, with peers.     Getting the APIs to parse correctly    We ran into a few challenges along the way, mainly dealing with the core structure of the game such as the game loop and rendering.  We didn't know how to use APIs or what language to even use at first. Getting a useable frame rate, organizing the application for platform expansion, and little time! We ran into challenges surrounding the limitations of JavaScript in editing the XML file.  Visualizing the data was more complex than we anticipated, and promptly ran out of time.   It was my first time making an actual project on an Arduino, and I had never really used Flask before. In the process of making the site, I ran into several production issues with Ngrok. Additionally, I encountered difficulties connecting to the development server on several instances, and the Twilio versioning proved challenging for the back-end.  I never have programmed for a database before in the cloud, never have done anything with AI or any scraping of anything online. I only had Java experience and iOS app experience from previous HackPSU's. I was somehow able to get the AI to work, send data to MongoDB, and bring that data back to the java application to be viewed by the user. I slept just under 3 hours.  We ran into lots of challenges getting the APIs to work with each other. We also ran into difficulty integrating HTML, Java, and Javascript to run together well. Some challenges that we have faced: finding an effective way to lay out the step-by-step process for a user who is utilizing the website. Also, we struggled with the level of technical knowledge within our group.   I was having trouble displaying location of other users.Also had trouble displaying my own location and updating annotations. The first challenges we ran into is that because most of us are novice hackers, we had to learn html, css, and js and the combination of the three to build a chrome extension website. We had to learn how to build progress bars, how to overlay chrome extension pages, how to use the chrome storage, and how to even modify the amazon website, and much more.We constantly ran into errors, debugging problems, buttons overlapping, text not formatting, connecting different files in our project and many more. We wanted to make something that worked, yet didn’t want to make it out of the scope of our abilities. Using MapBox APIs. Connecting and setting up database.Understanding Android Studio.Combining design with code. None One of the major difficulties in implementing the drivability score was the lack of historical data and crash statistics for tuning the regression coefficients used to factor the score.  This model will need to be improved in the future though more powerful APIs and larger datasets.  We ran into many challenges in compiling the code. The coding part was the most grueling due to the nature of blockchains and our previous inexperience in ever creating a blockchain. However, we were able to learn many things about how the code behind a blockchain works. Specifically, we ran into challenges with abstracting the code and having the main Java class, where the interaction of a person making a transaction is made, triggers the addition of a new block in the blockchain. We also had difficulty abstracting most of the code into more efficient classes and methods so we could solve the previously mentioned problem. We had to figure out how to use Twilio. Another challenge we faced was linkingour HTML pages to our python. Connecting everything   From the start, we had no prior experience working with some apis and services. We had trouble retrieving data from google firebase. We had trouble determining the best way to cluster data points. Taking user inputs and predicting the weather inputs was also a challenge.   deciding on the project! We pivoted a couple of times  How to get data and how to display data.    It was tough to get this done in 24 hours, for one! I think that the most difficult part of getting this project done was handling the relay of completed events using the Java API. Creating the API, gathering data, and handling dataflow in iOS were the most challenging aspects of this project. Although we knew Python beforehand, applying this knowledge and creating a RESTful API service using Flask as the backend was a new area for all of us and had many challenges as well. Further, although there are many databases available about food nutrition, there is not nearly as much about expiration dates since they are not federally regulated and depend on the manufacturer's discretion. Thus, we had to use web scraping to gather our own data as curated datasets were not available. The dataflow in iOS was also one of the biggest challenges we faced since SwiftUI is a relatively new platform and there are many differences in it, especially how the dataflow is handled.    The main challenge we encountered (and overcame) was learning how to use APIs through the Unirest library, as no one on our team had any prior experience dealing with APIs before this event. Certain programs were still on the site, despite no longer being programs run at Shodor. The design of the original website was also confusing in the way that navigation/links were set up for users to explore opportunities.  Limited clean datasets.Hyper parameter tuning to build a top-class model.Sleepless night. The first challenge is the limitation of ARFundation in terms of its transform systems since the orientation of the spawned objects are restricted. To create the effect of having a portal we have to use shader to modify the underlying rendering pipeline to present the "illusion" of seeing things from a restricted window. The fact that we need to render massive scenes behind the portal increased the difficulty due to performance problems.  Formatting the data was a challenge because there were a lot of columns that had information that was not relevant to our visualizations. There were also differentiations in the way counties were named and we had to standardize it. Accomplishments that we’re proud ofWe were able to code this web app with our team being at least 50% novice.What we learnedWe learned a lot about R, HTML, .csv files, pandas, Python, Github and most importantly, how to work as a team!What’s next for On The MoveIdeally, we would love to have more features like 3-D visualizations and more datasets. Given more time, we would add a feature that includes a ranking of the best counties based on all of the features we have.Built Withcssdatahtmljavascriptjupyter-notebooknode.jspythonrTry it outgithub.com      Submitted to    HackDuke: Code for Good 2019    Created by  I worked on front-end. Using HTML and CSS I helped design an interactive website that linked with our web app. Alvin BaoI worked on the front-end. Using HTML and CSS, I designed a website that holds the data visualizations and other information on the web app. Stephanie YaoI built the structure of the web app using Shiny in R to create the auto-generating visualizationsKeshav ShenoyI worked on gathering and parsing data, along with finding insights. I mainly worked with data analytics in Python.Ayush GoyalI worked on handling and parsing sets of data to allow data visualizations to be created. I mainly worked with python and its libraries for data analysis.Richik Ray   I found it extremely difficult to create the project on my own.  Nobody knew Django until today. The framework that we based our application on was unable to conform within our design process. Figuring out how to connect to the SmartCar API was difficult.  The first challenge we met was that the request sent by Apex function cannot be received by the local server. The second challenge was that we are unable to generate reports crossing multiple database tables.   Initially we wanted to use Salesforce to serve as the database and the hub for all the data that we would pull in from Google; however, we ran into some serious troubles after several hours of being unable to complete the OAuth2 step to connect with their API. After we realized that we would most likely be unable to meet the deadline if we continued using going this route, we shifted gears completely and decided to reconstruct a solution using React as the frontend.   MacOS build was broken, so had to work with CODA team to set up alternative. Also was expecting more data to be returned from query.  One of the greatest challenges we stumbled across in the development of ConnectMe was the integration of the Twilio API into Google App Engine. It was difficult juggling two documentations and libraries within each other.   Google App Engine does not like python and javascript Finding recent and authentic datasetsIndexing at scale takes a lot of time and infrastructure, for personal PCsUnderstanding Visualization libraries, for users to easily understand I ran into one issue in particular the first night. I could not get the questions to appear one after the other and store the user's input at the same time. I took a break, went to sleep, and figured it out in my dreams. Learning React, figuring out how to manage the states Finding APIs to scrape for airport restaurant data.   Sending information between devices without pairing  Lots of moving parts, with 5 different repos. Lots to take in without context. Great project though. we intended to use IBC to connect to the DEX and query price data in order to mint new reDAOmint shares using a bonding curve. It proved impossible to integrate IBC with the DEX code due to its usage of an old version of the Cosmos SDKwe didn't have time to implement IBC methods for staking delegation and withdrawing rewardsthe IBC support is generally at an early stagewe don't actually have an on-chain geospatial index and that is a project of its ownthe bank and supply modules don't provide an efficient way to query the holders of just a single asset - this is something we would like to improve in the futuresimply not enough time for testing and debugging everything!   [x] Getting the application deployed to Heroku[x] Preprocessing the data so that tfjs can use it without errors still is finicky[x] Having the native Geolocator to work, navigator.geolocation((loc) =>  loc.coords) we scraped that Understanding the scope of Payroll decentralisation  Configuaration of the hyperledger network as it's quite complicated   We ran into challenges with the authentication, the database, the API and creating the categories The learning curve of the completely new tech stack that we are building. Google Databases. not too much doc and new to js Unfortunately we're all first and second year computer science students with very minimal knowledge in using app development frameworks so we went ahead and created a visual high fidelity prototype that showcases what we want to accomplish.  Indexing things is hard. Parsing big data is annoying. Dash applications do not like to be pretty. Orbits aren't easy. Front-end: Interacting with the smart contract through web3 library on the react app was challenging as some of the web3 functions were not included in the base node modules.Back-end: Breaking changes to Solidity depending on version and compiler. Generating factory contracts and lack of error messages. Flash loans are new so documentation is sparse so we were paving our own way.   Picking the right software for the backend. We started off using elixir, scrapped it to build it in express and mysql instead, and then scrapped that to use django and sqllite.  -Tool compatibility    Excel filters not hiding values from Figma- The Noun Project    For sourcing visual assets- Material Design User Interface Kit    A library of UI elements, app templates and style guides combined into a source file for Figma -Data sourcing    Finding reputable, current, and relevant climate data.-scope creep    Staying focused on creating a prototype that demonstrates core features,not getting distracted with extras.-time estimations    Setting realistic goals about what we could build in the alloted time.-communicating our missionTrying to refine our message to convey both the immediate problem solved by the app as well as the larger context of the app.  This was my first time using React as a front-end templating framework as well as the Google Maps API. In comparison to VueJS, React does not provide as much control over your application. The Google Maps API, in particular, was difficult to work with because there was a lot of things you couldn't do to customize it. Furthermore, I worked on this project alone for the entirety of the hackathon. Serialization issues in Cosmos. Needs moar logging Float points came to bug here as well. Need to expand the logic to allow for fractional interest rates. Also need to refactor the json formatting to allow for block-times to be included so that the chain could calculate correct interest rates from the start time of the borrow position.  Creating the rectangle selector for pinpointing different Placing the python script to call the API on the cloud was difficult as the documentation and setup were unclear. It took us a while to configure the cloud properly for use. In addition, the script took a while to be registered on the cloud which slowed down our debugging process. Also, the Google Cloud Vision process had common errors at times, which had to be manually fixed through string parsing algorithms. We originally wanted to have almost everything be hosted in Google Cloud, including the back end, database, and front end. We ran into a lot of issues in trying to figure out how to get different parts of the project to communicate, and so in the end, as we began to run low on time, we decided to use a more simplified version for the final submission. No one on our team was very familiar with Javascript, which is what Chrome extensions are built with. We spent a lot of time learning the fundamentals of this language. We also had difficulty finding good sources of data to pull from.  We found it difficult to train the machine learning model which faced inaccuracies due to training data (movie reviews) that isn't completely compatible with sentiment  Towards the end issues with SSL prevented us from linking the AR dashboard to the GIS API. We also had difficulties using the AR web app on a variety of devices due to nuances in gyroscope function. The server was bad. We don't have an all encompassing data set.  We ran totally into the Capital One challenge. Also we got into the Home Depot challenge, because we think that Ethereum connected to your bank account is a very good opportunity to provide better financial inclusion, and can provide value for companies by allowing payments in Ethereum/backed crypto. Front-End: Working with MaterialUI, general styling and designBack-End: Getting RabbitMQ to work with Java and Go Some challenges we faced were inputting the users input from the app into the correct pages that go for each category. This problem was specific to android studio since it converted the strings into bytes.  